{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma7jr/102003703Sampling/blob/main/Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the z-value and margin of error for each sampling technique\n",
        "z = 1.96  # 95% confidence interval\n",
        "m = 0.05  # margin of error\n",
        "\n",
        "# Calculate the sample size for each sampling technique using the formula\n",
        "n1 = int(np.ceil((z**2 * 0.5 * 0.5) / (m**2)))\n",
        "n2 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n3 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n4 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n5 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "\n",
        "# Define the sampling techniques and models\n",
        "sampler1 = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
        "sampler2 = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "sampler3 = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "sampler4 = TomekLinks(sampling_strategy='majority')\n",
        "sampler5 = NearMiss(version=3, n_neighbors=3)\n",
        "\n",
        "model1 = LogisticRegression(random_state=42,max_iter=800)\n",
        "model4=GradientBoostingClassifier(random_state=42)\n",
        "model3 = ExtraTreesClassifier(random_state=42)\n",
        "model2 =XGBClassifier(random_state=42)\n",
        "model5 = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Define a dictionary to hold the sampling techniques and models\n",
        "samplers = {\n",
        "    'Sampling1': sampler1,\n",
        "    'Sampling2': sampler2,\n",
        "    'Sampling3': sampler3,\n",
        "    'Sampling4': sampler4,\n",
        "    'Sampling5': sampler5,\n",
        "}\n",
        "models = {\n",
        "    'M1': model1,\n",
        "    'M2': model2,\n",
        "    'M3': model3,\n",
        "    'M4': model4,\n",
        "    'M5': model5,\n",
        "}\n",
        "\n",
        "# Evaluate each model on each sampling technique\n",
        "results = {}\n",
        "for sampler_name, sampler in samplers.items():\n",
        "    if sampler_name == 'Sampling1':\n",
        "        n = n1\n",
        "    elif sampler_name == 'Sampling2':\n",
        "        n = n2\n",
        "    elif sampler_name == 'Sampling3':\n",
        "        n = n3\n",
        "    elif sampler_name == 'Sampling4':\n",
        "        n = n4\n",
        "    else:\n",
        "        n = n5\n",
        "\n",
        "    # Undersample or oversample the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    \n",
        "    # Limit the resampled data to the sample size\n",
        "    if len(X_resampled) > n:\n",
        "        X_resampled = X_resampled[:n]\n",
        "        y_resampled = y_resampled[:n]\n",
        "    \n",
        "    for model_name, model in models.items():\n",
        "        # Train the model on the resampled data\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        \n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate the accuracy score\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        \n",
        "        # Add the accuracy score to the results dictionary\n",
        "        if model_name in results:\n",
        "            results[model_name][sampler_name] = accuracy\n",
        "        else:\n",
        "            results[model_name] = {sampler_name: accuracy}\n",
        "            \n",
        "# Print the results\n",
        "print('Results:')\n",
        "print('        Sampling1   Sampling2   Sampling3   Sampling4   Sampling5')\n",
        "for model_name, model_results in results.items():\n",
        "    print(model_name, end='')\n",
        "    for sampler_name in samplers.keys():\n",
        "        if sampler_name in model_results:\n",
        "            print(f'    {model_results[sampler_name]:.4f}   ', end='')\n",
        "        else:\n",
        "            print('              ', end='')\n",
        "    print() "
      ],
      "metadata": {
        "id": "0BVJSx8vwNad",
        "outputId": "98404857-caf9-4740-9bc8-06fdff6e7845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "        Sampling1   Sampling2   Sampling3   Sampling4   Sampling5\n",
            "M1    0.5742       0.9935       0.9935       0.9935       0.3742   \n",
            "M2    0.6903       0.9935       0.9935       0.9935       0.8452   \n",
            "M3    0.8065       0.9935       0.9935       0.9935       0.6516   \n",
            "M4    0.5742       0.9935       0.9935       0.9935       0.8387   \n",
            "M5    0.5742       0.9935       0.9935       0.9935       0.8323   \n"
          ]
        }
      ]
    }
  ]
}